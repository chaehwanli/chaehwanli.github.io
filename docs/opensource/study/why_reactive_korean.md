---
layout : default
title : Why Reactive 번역
parent : Study
grand_parent : OpenSource
---


[Why Reactive](https://www.oreilly.com/content/why-reactive/)

Introduction
>It’s increasingly obvious that the old, linear, three-tier architecture model is obsolete.
오래되고 선형인 3계층 아키텍처 모델이 더 이상 쓸모가 없다는 것이 점점 더 명백해지고 있습니다.
A Gartner Summit track description

반응형이라는 용어는 오랫동안 사용되어 왔지만, 최근에야 업계에서 시스템 설계를 발전시키는 실질적인 방법으로 인식하고 주류 채택을 하게 되었습니다. 2014년 Gartner는 그토록 인기가 있었던 3계층 아키텍처가 이제 그 시대를 열기 시작했다고 썼습니다. 이 보고서의 목표는 과대 광고에서 한 걸음 물러나서 반응성이 실제로 무엇인지, 언제 채택해야 하는지, 어떻게 수행해야 하는지 분석하는 것입니다. 이 보고서는 반응 응용 프로그램 및 시스템 설계의 기본 원칙에 중점을 두고 대부분 기술에 구애받지 않는 것을 목표로 합니다. 분명히 Lightbend 또는 Netflix 스택과 같은 특정 최신 기술은 다른 기술보다 Reactive Systems 개발에 훨씬 더 적합합니다. 그러나 이 보고서는 빈 권장 사항을 제공하는 대신 필요한 배경과 이해를 제공하여 스스로 올바른 결정을 내릴 수 있도록 합니다.

이 보고서는 리액티브가 무엇인지 알고자 하는 기술적인 배경을 가진 CTO, 설계자, 팀 리더 또는 관리자를 대상으로 합니다. 일부 장에서는 기술적인 측면에 대해 자세히 설명합니다. Application 수준에서 반응을 다루는 (application 수준에서 반응에서) 우리는 이 프로그래밍 패러다임과 리소스 활용에 미치는 영향에 대한 기술적 차이점을 이해해야 합니다 다음 장에서는 시스템 수준에서의 반응에 대해 한 걸음 물러서서 분산 반응 응용 프로그램의 구조적 영향과 조직적 영향을 살펴봅니다. 마지막으로, 우리는 몇 가지 마무리 생각으로 보고서를 마무리하고 몇 가지 빌딩 블록과 주제에 대한 모든 마케팅 과대 광고 중에서 반응형 아키텍처에 정말 적합한 것을 찾는 방법을 제안합니다.

그렇다면 반응형은 실제로 무엇을 의미합니까? 그 핵심 의미는 2013년 Jonas Bonér가 분산 및 고성능 컴퓨팅 업계에서 가장 명석한 사람들을 모은 2013년 Reactive Manifesto의 작성으로 다소 형식화되었습니다. 즉, 알파벳 순서로 Dave Farley, Roland Kuhn 및 Martin Thompson - 반응형 응용 프로그램 및 시스템을 구축하기 위한 핵심 원칙이 무엇인지 협력하고 공고히 합니다. 목표는 리액티브를 둘러싼 혼란을 명확히 하고 실행 가능한 개발 스타일에 대한 강력한 기반을 구축하는 것이었습니다. 이 보고서에서 선언문 자체를 깊이 있게 다루지는 않겠지만 읽어볼 것을 강력히 권장합니다. 오늘날 시스템 설계에 사용되는 많은 어휘(예: 오류와 실패의 차이)가 잘 정의되어 있습니다.

Reactive Manifesto가 용어에 대한 혼란을 명확히 하기 위해 출발한 것처럼, 이 보고서의 목표는 반응적이라는 것이 무엇을 의미하는지에 대한 공통된 이해를 확고히 하는 것입니다.

Why Build Reactive Systems?
>It’s no use going back to yesterday, because I was a different person then.
어제로 돌아가도 소용없어 그때의 나는 다른 사람이었으니까.
Lewis Carroll

Reactive Systems 및 아키텍처의 기술적인 측면에 뛰어들기 전에 “Reactive Systems를 구축하는 이유는 무엇입니까?”라고 자문해 보아야 합니다.

수년간 애플리케이션을 구축하는 방식을 변경하는 데 관심을 갖는 이유는 무엇입니까? 또는 더 나은 방법으로 "우리 소프트웨어 사용자에게 어떤 이점을 제공하려고 합니까?"라는 질문으로 토론을 시작할 수 있습니다. 가능한 많은 답변 중에서 일반적으로 누군가가 Reactive Systems 디자인을 조사하기 시작하도록 유도하는 몇 가지가 있습니다. 우리 시스템이 다음을 수행해야 한다고 가정해 보겠습니다.

- 사용자와의 상호 작용에 응답하십시오.
- 장애를 처리하고 정전 중에도 계속 사용 가능
- 다양한 부하 조건에서 노력
- 다양한 네트워크 조건에서 메시지를 보내고 받고 라우팅할 수 있습니다.

이러한 답변은 실제로 선언문에 정의된 핵심 반응 특성을 전달합니다. 응답성은 우리 애플리케이션의 하드웨어 활용도를 제어함으로써 달성되며, 많은 반응 기술이 훌륭한 도구입니다. 우리는 애플리케이션 레벨에서 반응성을 보기 시작할 때 애플리케이션 레벨에서 반응성에서 몇 가지를 봅니다. 한편, 시스템을 쉽게 확장할 수 있도록 하는 좋은 방법은 시스템의 일부를 분리하여 독립적으로 확장할 수 있도록 하는 것입니다. 이러한 방법을 시스템 간의 동기 통신을 피하는 것과 결합하면 이제 시스템을 보다 탄력적으로 만들 수 있습니다. 가능하면 비동기식 통신을 사용하면 수명 주기를 요청의 대상 호스트 수명 주기에 엄격하게 바인딩하는 것을 피할 수 있습니다. 예를 들어 수명 주기가 느리게 실행되는 경우 영향을 받지 않아야 합니다. 다른 문제와 함께 Reactive on the System Level에서 시스템 수준에서 축소하고 반응에 집중할 때 동기식 요청-응답 통신 패턴을 비동기식 메시지 전달과 비교하여 이 문제를 검토할 것입니다.

마지막으로 반응 시스템의 빌딩 블록에서 도구 상자에 다양한 도구를 나열하고 각 도구를 언제 어떻게 사용해야 하는지에 대해 설명합니다. 또한 현실 세계가 우리가 통합하고자 하는 기존의 가치 있는 시스템으로 가득 차 있음을 인정하면서 기존 코드 기반에 반응형을 도입하는 방법에 대해 논의합니다.

And Why Now?
> The Internet of Things (IoT) is expected to surpass mobile phones as the largest category of connected devices in 2018.
Ericsson Mobility Report

"왜"라는 질문의 또 다른 흥미로운 측면은 조금 더 나아가 "왜 지금?"이라고 물을 때 드러납니다.

곧 알게 되겠지만, 반응형 이면의 많은 아이디어는 그렇게 새롭지 않습니다. 그들 중 많은 것들이 몇 년 전에 설명되고 구현되었습니다. 예를 들어, Erlang의 액터 기반 프로그래밍 모델은 1980년대 초부터 존재해 왔으며 최근에는 Akka와 함께 JVM에 도입되었습니다. 따라서 질문은 다음과 같습니다. 왜 그토록 오랫동안 존재해 왔던 아이디어가 주류 엔터프라이즈 소프트웨어 개발에 적용되고 있습니까?

확장성 및 분산 시스템이 이전에는 단일 상자에서 또는 너무 많은 확장 또는 하드웨어 활용 없이 생존할 수 있었던 많은 애플리케이션에서 일상적인 빵과 버터가 된 흥미로운 시점에 있습니다. 현재 반응 프로그래밍이 부상하는 데 많은 움직임이 기여했으며, 특히 다음과 같습니다.

사물인터넷과 모바일
모바일 부문은 2015년 1분기와 2016년 1분기 사이에 트래픽이 60% 증가했습니다. Ericsson Mobility Report에 따르면 이러한 성장은 조만간 둔화될 조짐을 보이지 않습니다. 이러한 섹터는 정의상 서버 측에서 수백만 개의 연결된 장치를 동시에 처리해야 함을 의미합니다. 작업은 "장치"와 같은 리소스를 나타내는 경량 기능으로 인해 비동기 처리로 가장 잘 처리됩니다.

클라우드 및 컨테이너화
우리는 수년 동안 클라우드 기반 인프라를 보유하고 있지만 컨테이너 중심 스케줄러 및 PaaS 솔루션과 함께 경량 가상화 및 컨테이너의 등장으로 훨씬 더 빠르고 정밀한 배포를 위한 자유와 세분화된 범위의 속도를 얻었습니다. 
이 두 가지 움직임을 살펴보면 동시 및 분산 응용 프로그램에 대한 필요성이 점점 더 커지고 있는 시점에 있음이 분명합니다. 동시에 큰 번거로움 없이 대규모로 이를 수행하는 데 필요한 도구가 마침내 따라잡고 있습니다. 우리는 몇 년 전과 같은 위치에 있지 않습니다. 분산 애플리케이션을 배포할 때 가능한 한 배포 및 인프라 자동화 솔루션을 관리하는 전담 팀이 필요했습니다.

Reactive라는 운동 우산 아래에서 우리가 다시 방문하는 많은 솔루션이 1970년대부터 존재해 왔다는 것을 깨닫는 것도 중요합니다. 개념이 알려졌음에도 불구하고 반응형이 지금은 주류를 이루고 그때는 그렇지 않은 이유는 여러 가지와 관련이 있습니다. 첫째, 더 나은 리소스 활용 및 확장성에 대한 요구가 대부분의 프로젝트에서 솔루션을 찾을 만큼 강력해졌습니다. 도구는 클러스터 스케줄러, 메시지 기반 동시성 및 Akka와 같은 배포 도구 키트와 함께 이러한 많은 솔루션에도 사용할 수 있습니다. 다른 흥미로운 측면은 Reactive Streams와 같은 이니셔티브를 사용하면 모든 구현이 우수한 상호 운용성을 제공하는 것을 목표로 하기 때문에 특정 구현에 고정될 위험이 적다는 것입니다. 다음 장에서 Reactive Streams 표준에 대해 좀 더 자세히 논의할 것입니다.

다시 말해, 배포 및 인프라에서 더 많은 자동화를 향한 지속적인 움직임으로 인해 여러 전문 서비스에 분산된 응용 프로그램을 서로 다른 노드에 분산시키는 것이 마찰이 없어져 이러한 도구를 채택하는 것이 더 이상 소규모 팀의 장애물이 되지 않는 위치에 이르렀습니다. 이러한 경향은 최근의 서버리스(Ops-less) 운동의 부상으로 수렴되는 것으로 보입니다. 이 움직임은 모든 팀이 자체적으로 클라우드를 자동화하는 다음 논리적 단계입니다. 그리고 여기에서 반응적 특성이 지금 당장 성공할 수 있을 뿐만 아니라 위치 투명하고 무작동 분산 서비스를 향한 업계의 방향과도 잘 맞아떨어진다는 사실을 깨닫는 것이 중요합니다.

Reactive on the Application Level
>The assignment statement is the von Neumann bottleneck of programming languages and keeps us thinking in word-at-a-time terms in much the same way the computer’s bottleneck does.
대입문은 프로그래밍 언어의 폰 노이만 병목 현상이며 컴퓨터의 병목 현상과 거의 동일한 방식으로 한 번에 단어 단위로 생각하게 합니다.
John Backus

Reactive Systems를 구축하기 위한 첫 번째 단계로 이러한 원칙을 단일 애플리케이션에 적용하는 방법을 살펴보겠습니다. 많은 원칙이 이미 시스템의 로컬(애플리케이션) 수준에 적용되며, 반응적인 빌딩 블록에서 시스템을 아래에서 위로 구성하면 동일한 아이디어를 완전한 분산 시스템으로 간단하게 확장할 수 있습니다.

먼저 두 개의 별개 커뮤니티가 최근에 그 사용에 대해 동의하기 시작하기 전에 "반응성"이라는 단어를 사용할 때 발생하는 일반적인 오해를 수정해야 합니다. 한편으로, 업계, 특히 ops 세계는 오류에 직면했을 때 치유할 수 있거나 직면하거나 트래픽 증가/감소에 직면하여 확장할 수 있는 시스템을 "반응형 시스템"으로 오랫동안 언급해 왔습니다. 이것은 Reactive Manifesto의 핵심 개념이기도 합니다. 반면에 학계에서는 "FRP(Functional Reactive Programming)" 또는 보다 구체적으로 "Functional Reactive Activation"이라는 용어가 만들어진 이후로 "Reactive"라는 단어를 사용하고 있습니다. 이 용어는 1997년 Haskell 및 이후 Elm, .NET(여기서 "Reactive Extensions"라는 용어가 알려짐) 및 기타 언어에서 도입되었습니다. 이 기술은 실제로 반응 시스템에 매우 유용합니다. 그러나 오늘날에는 FRP 프레임워크 자체에서도 잘못 해석되고 있습니다.

반응형 프로그래밍의 핵심 요소 중 하나는 작업을 비동기적으로 실행할 수 있다는 것입니다. 최근 FRP 기반 라이브러리의 인기가 높아짐에 따라 많은 사람들이 이전에 FRP만 알고 리액티브하게 되었고 이것이 Reactive Systems가 제공해야 하는 모든 것이라고 가정합니다. 이벤트 및 스트림 처리가 그 중 큰 부분을 차지하지만 반드시 반응의 요구 사항이나 전체가 아니라고 주장합니다. 예를 들어, 반응형 애플리케이션 및 프로그래밍에 매우 적합한 액터 모델(Akka 또는 Erlang에서 알려짐)과 같은 다양한 다른 프로그래밍 모델이 있습니다.

반응형 라이브러리 및 구현의 일반적인 주제는 일종의 이벤트 루프 또는 스레드 풀을 기반으로 하는 공유 디스패처 인프라를 사용하는 경우가 많다는 것입니다. 간단한 작업, 액터 또는 공유 디스패처에서 호출되는 일련의 콜백 등 값싼 구성 간에 값비싼 리소스(예: 스레드)를 공유하기 때문에 이러한 기술을 사용하면 단일 애플리케이션을 여러 코어에 걸쳐 확장할 수 있습니다. 이러한 다중화 기술을 통해 이러한 라이브러리는 단일 상자에서 수백만 개의 엔티티를 처리할 수 있습니다. 덕분에 갑자기 우리 시스템에서 사용자당 하나의 액터를 가질 수 있게 되었고, 액터를 사용한 도메인 모델링도 더 자연스러워졌습니다. 일반 스레드를 직접 사용하는 응용 프로그램에서는 너무 빨리 무거워지기 때문에 깨끗한 분리를 얻을 수 없습니다. 또한 스레드에서 직접 작업하는 것은 간단한 문제가 아니며 실제 비즈니스 로직을 수행하는 데 집중하는 대신 다른 스레드 간에 데이터를 동기화하려는 코드가 대부분의 프로그램을 빠르게 지배합니다.

단점, 그리고 무엇이 새로운 "빌드를 깨뜨렸습니까?!"가 될 수 있습니다. 우리 시대는 "누가 이벤트 루프를 차단했습니까?!"라는 문구에 요약되어 있습니다. 차단이란 완료하는 데 오랜(무한한) 시간이 걸리는 작업을 의미합니다. 문제가 있는 차단의 일반적인 예에는 차단 드라이버(가장 최신 데이터베이스 드라이버가 있음)를 사용한 파일 I/O 또는 데이터베이스 액세스가 포함됩니다. 차단 문제를 설명하기 위해 그림 2-1의 다이어그램을 살펴보겠습니다. 두 개의 실제 단일 코어 프로세서가 있고(단순화를 위해 하이퍼 스레딩 또는 이와 유사한 기타 기술을 사용하지 않는다고 가정) 처리하려는 작업 대기열이 세 개 있다고 상상해 보십시오. 모든 대기열은 거의 동등하게 중요하므로 최대한 공정하고 빠르게 처리하고자 합니다. 공정성 요구 사항은 차단 기술을 사용하여 프로그래밍할 때 종종 생각하지 않는 것입니다. 그러나 일단 비동기식으로 전환하면 점점 더 중요해지기 시작합니다. 명확히 하자면, 그러한 시스템의 공정성은 모든 대기열의 서비스 시간이 거의 동일하다는 속성입니다. "더 빠른" 대기열은 없습니다. 그림 2-1의 각 타임라인에 있는 색상은 주어진 순간에 해당 프로세스를 처리하는 프로세서를 강조 표시합니다. 우리의 가정에 따르면 두 프로세스만 병렬로 처리할 수 있습니다.

![Image](..\images\why_reactive_2-1.png)
Figure 2-1. 여기에 회색으로 표시된 차단 작업은 전체 시스템 공정성과 특정(불운) 사용자의 인지된 응답 시간에 영향을 미치는 리소스를 낭비합니다.

회색 영역은 아래 행위자가 차단 API를 사용하여 파일이나 네트워크에 데이터 쓰기를 시도하는 것과 같은 일부 차단 작업을 실행했음을 나타냅니다. 이제 세 번째 액터가 CPU 리소스로 실제로 아무 것도 하지 않는다는 것을 알 수 있습니다. 차단 호출의 반환을 기다리는 데 낭비되고 있습니다. Reactive Systems에서는 이러한 작업을 수행할 때 스레드를 풀에 다시 제공하여 중간 액터가 메시지 처리를 시작할 수 있도록 합니다. 차단 작업으로 인해 중간 대기열에서 기아 현상이 발생하고 중간 행위자가 처리하는 요청의 응답 대기 시간과 함께 전체 시스템의 공정성을 모두 희생합니다.

어떤 사람들은 관찰과 도표를 "차단하는 것은 순전히 악이고 모든 것이 파멸이다!"로 잘못 해석합니다. 때때로 반응 기술의 반대자는 이 문구를 사용하여 보다 현대적인 반응 기술 스택에 대한 두려움, 불확실성 및 의심(일명 FUD, 공격적인 마케팅 방법론)을 퍼뜨립니다. 메시지가 실제로(그리고 항상 그랬듯이) 차단하려면 세심한 관리가 필요합니다!

많은 반응형 툴킷(Netty, Akka, Play 및 RxJava 포함)이 차단 작업을 처리하는 데 사용하는 솔루션은 차단 동작을 차단 작업 전용인 다른 스레드 풀로 분리하는 것입니다. 이 기술을 샌드박싱 또는 벌크헤딩이라고 합니다. 그림 2-2에서 업데이트된 다이어그램을 볼 수 있습니다. 이제 프로세서는 실제 코어를 나타내며 처음부터 스레드 풀에 대해 이야기해 왔습니다. 두 개의 스레드 풀이 있습니다. 기본 스레드 풀은 노란색이고 새로 생성된 스레드 풀은 차단 작업을 위한 회색입니다. 차단 호출을 발행하려고 할 때마다 대신 해당 풀에 넣습니다. 세 번째 프로세스가 차단 작업의 응답을 기다리는 동안 나머지 응용 프로그램은 기본 풀에서 계속해서 메시지를 처리할 수 있습니다. 명백한 이점은 차단 작업이 주 이벤트 루프 또는 디스패처를 지연시키지 않는다는 것입니다.

그러나 이러한 분리에는 더 많거나 덜 분명한 이점이 있습니다. 그 중 하나는 비동기식 응용 프로그램으로 더 많이 작업하기 전에는 이해하기 어려울 수 있지만 실제로는 매우 유용합니다. 이제 서로 다른 풀에서 서로 다른 유형의 작업을 분리했으므로 풀이 과부하되는 것을 발견하면 애플리케이션의 병목 현상이 방금 발생한 위치를 즉시 알 수 있습니다. 또한 풀에 엄격한 상한선을 설정하여 허용되는 무거운 작업 수 이상을 실행하지 않도록 할 수 있습니다. 예를 들어 모든 CPU 집약적 작업에 대해 디스패처를 구성하는 경우 코어가 4개뿐이라면 이러한 작업 중 20개를 동시에 시작하는 것은 의미가 없습니다.

![Image](..\images\why_reactive_2-2.png)
Figure 2-2. 차단 작업은 전용 디스패처(회색)에서 예약됩니다. 기본 디스패처(노란색)에서 정상적인 반응 작업이 방해받지 않고 계속될 수 있도록

In Search of the Optimal Utilization Level
이전 섹션에서 비동기 API와 프로그래밍 기술을 사용하면 하드웨어 활용도를 높이는 데 도움이 된다는 것을 배웠습니다. 이것은 좋은 소리이며 실제로 우리는 우리가 지불하는 하드웨어를 최대한 사용하고 싶습니다. 그러나 동전의 다른 측면은 사용률을 특정 지점 이상으로 밀면 수익이 감소한다는 것입니다(더 밀면 마이너스까지). 이 관찰은 1993년 Neil J. Gunther에 의해 공식화되었으며 USL(Universal Scalability Law)이라고 합니다.

USL, Amdahl의 법칙, 큐잉 이론의 관계는 그 자체로 전체 논문의 가치가 있는 자료이므로 이 보고서에서는 몇 가지 간단한 직관만 제공합니다. 이 섹션을 읽은 후 흥미를 느끼고 더 자세히 알고 싶다면 Baron Schwartz(O'Reilly)의 백서 "Universal Scalability Law를 사용한 Practical Scalability Analysis"를 확인하십시오.

USL은 1967년 Gene Amdahl이 처음 정의한 더 널리 알려진 Amdahl의 법칙보다 더 실용적인 모델로 볼 수 있습니다. 이 법칙은 병렬로 실행할 수 있는 양에 따라 알고리즘의 이론적 속도 향상에 대해서만 이야기합니다. 반면에 USL은 인용문에서 변수로 통신 비용, 데이터 동기화 유지 비용(일관성)을 도입함으로써 분석을 한 단계 더 발전시켰으며, 시스템을 활용 스위트 스폿 이상으로 밀어붙이는 것이 모든 종류의 조정이 백그라운드에서 발생하기 때문에 실제로는 시스템의 전체 처리량에 부정적인 영향을 미칩니다. 이러한 조정은 하드웨어 수준(예: 메모리 대역폭 포화, 프로세서 수와 분명히 비례하지 않음) 또는 네트워크 수준(예: 대역폭 포화 또는 인캐스트 및 재전송 문제)에 있을 수 있습니다.

우리는 다양한 자원을 놓고 경쟁할 수 있으며 과잉 사용 문제는 CPU뿐만 아니라 유사한 맥락에서 네트워크 자원에도 적용된다는 점에 유의해야 합니다. 예를 들어, 처리량이 많은 메시징 라이브러리 중 일부를 사용하면 다양한 클라우드 제공업체 설정에서 가장 일반적으로 발견되는 1Gbps 네트워크를 최대화할 수 있습니다(10Gbps와 같은 특정 네트워크/노드 구성을 사용할 수 있고 프로비저닝하지 않는 한 Amazon EC2의 특정 고급 인스턴스에 사용할 수 있는 네트워크 인터페이스). 따라서 USL은 로컬 및 분산 설정 모두에 적용되지만 지금은 USL의 애플리케이션 수준 의미에 초점을 맞추겠습니다.

Using Back-Pressure to Maintain Optimal Utilization Levels
동기식 API를 사용할 때 시스템은 차단 작업에 의해 "자동으로" 역압력을 받습니다. 차단 작업이 완료될 때까지 다른 작업을 수행하지 않기 때문에 기다리면서 많은 리소스를 낭비하고 있습니다. 그러나 비동기식 API를 사용하면 다른 (느린) 다운스트림 시스템이나 애플리케이션의 다른 부분을 압도할 위험이 있지만 로직을 더욱 강력하게 수행할 수 있습니다. 여기서 역압(또는 흐름 제어) 메커니즘이 작동합니다.

Reactive Manifesto와 유사하게 Reactive Streams 이니셔티브는 제한된 메모리 스트림 처리와 관련된 상호 운용성 프로토콜을 표준화하고자 하는 동시 및 분산 애플리케이션을 구축하는 업계 선두 기업 간의 협력에서 시작되었습니다. 이 초기 협업에는 Lightbend, Netflix 및 Pivotal이 포함되었지만 결국 RedHat 및 Oracle의 개발자를 포함하도록 성장했습니다. 이 사양은 다양한 스트리밍 라이브러리 간의 저수준 interop 프로토콜을 목표로 하며 이러한 스트리밍 라이브러리의 사용자에게 백프레셔를 투명하게 적용해야 하며 이를 가능하게 합니다. 사양을 1년 넘게 반복한 결과,
TCK 및 Reactive Streams의 의미론적 세부 사항은 JEP-266 "추가 동시성 업데이트" 제안의 일부로 OpenJDK에 통합되었습니다. 이러한 인터페이스와 JDK 내부에서 직접 Java 에코시스템의 일부가 된 몇 가지 도우미 메서드를 사용하면 Reactive Streams 인터페이스를 구현하는 라이브러리에 베팅하여 JDK에 포함된 인터페이스로 이동할 수 있고 JDK9의 출시와 함께 미래에도 호환 가능합니다.

역압, Reactive Streams 또는 퍼즐의 다른 부분은 시스템을 복원력, 확장 가능 및 응답성을 만들기에 충분하지 않다는 점을 명심하는 것이 중요합니다. 여기에 설명된 기술의 조합으로 완전히 반응하는 시스템이 생성됩니다. 비동기식 및 역압식 API를 사용하여 시스템을 한계까지 밀어붙일 수 있지만 그 이상은 아닙니다. 트래픽의 갑작스러운 급증에 대처할 수 있는 능력과 자원 낭비 사이의 균형이 항상 중요하기 때문에 실제로 활용도가 얼마나 최적인지에 대한 질문에 답하는 것은 까다롭습니다. 또한 시스템이 수행하는 작업에 따라 크게 달라집니다. 시작하기 위한 간단한 경험 법칙(그 이후부터는 요구 사항에 따라 최적화)은 시스템 사용률을 80% 미만으로 유지하는 것입니다. 무엇보다도 활용 최적화를 위해 싸운 전투에 대한 흥미로운 논의는 우수한 Google Maglev 논문에서 읽을 수 있습니다.

이것이 "자신을 제한하는 것"이 ​​동기식 버전에 비해 전반적인 성능을 저하시킬 수 있는지 물어볼 수 있습니다. 예를 들어 단일 스레드, 원시 처리량 벤치마크에서 동기식 구현이 비동기식 구현을 능가하는 경우가 많습니다. 그러나 실제 워크로드는 그렇지 않습니다. Netflix에서 Tomcat과 비교한 RxNetty의 흥미로운 성능 분석에서 Brendan Gregg와 Ben Christensen은 비동기식 오버헤드 및 흐름 제어를 사용하더라도 비동기식 서버 구현이 동기식(및 고도로 조정된)톰캣 서버 보다 높은 부하에서 훨씬 더 나은 응답 대기 시간을 산출한다는 것을 발견했습니다. 

Streaming APIs and the Rise of Bounded-Memory Stream Processing

> Ever-newer waters flow on those who step into the same rivers.
Heraclitus

리액티브와 마찬가지로 스트리밍은 커뮤니티에서 "스트림"이라는 단어를 사용할 때 그 의미를 실제로 정의하려고 하는 단계에 있습니다. 슬프게도 사람들은 아마도 "반응적인" 것보다 그것에 대해 더 혼란스러워할 것입니다.
스트리밍 환경이 매우 혼란스러워진 이유는 매우 다른 요구 사항을 해결하는 여러 라이브러리에서 이 단어를 사용하게 되었기 때문입니다.
예를 들어 Spark Streaming과 Flink는 대규모 데이터 변환 측면을 다루지만 잘 알려진 Twitter 스트리밍 API와 같은 데이터 중소 규모 작업에는 적합하지 않습니다.

이 장에서 우리는 스트리밍이 실제로 무엇을 의미하는지, 왜 그것이 중요한지, 그리고 앞으로 일어날 일에 초점을 맞출 것입니다. 여기에는 동일한 코인의 양면이 있습니다. 스트리밍 API를 소비하고 생성하는 것입니다. API가 다양한 시스템 간의 통합 계층 역할을 하지만 시스템 수준이 아닌 응용 프로그램 수준에서 반응에 대해 장에서 이 주제를 논의하는 이유가 있습니다. 스트리밍 API 및 메모리 제한 처리가 제공하는 흥미로운 기능과 관련이 있습니다. 특히 스트리밍 라이브러리와 API를 사용 및/또는 구축하면 실제로 필요한 것보다 더 많은 데이터를 메모리에 로드할 수 없으므로 제한된 메모리 파이프라인을 구축할 수 있습니다. 이것은 주어진 연결 또는 스트림이 얼마나 많은 메모리를 사용하는지 보장하고 용량 계획 계산에 이 수치를 포함할 수 있으므로 용량 계획에 매우 흥미롭고 유용한 속성입니다.

Twitter Firehose API와 관련된 이 기능에 대해 논의해 보겠습니다. 이 API는 Twittersphere에서 수신되는 모든 트윗을 수집하고 분석하기 위해 애플리케이션이 구독할 수 있는 API입니다. 분명히 이러한 트래픽이 많은 스트림을 사용하려면 수신 측에서도 상당한 기계 전력이 필요합니다. 그리고 이것이 흥미로운 부분입니다. 다운스트림(Firehose API에 액세스하는 고객)이 방출되는 속도로 이를 소비할 수 없다면 어떻게 될까요?

서버의 관점에서 이 설계 과제를 살펴보겠습니다. 백엔드에서 들어오는 데이터의 라이브 스트림이 있으며 이를 서비스의 다운스트림 클라이언트로 푸시해야 합니다. 그들 중 일부는 느리거나 스트림을 전혀 소비하지 못하게 하는 끝에 문제가 있을 수 있습니다. 우리는 무엇을 해야 합니까? 일반적인 대답은 클라이언트가 돌아올 때까지 버퍼링하는 것입니다. 그 대답은 옳고 동시에 두려운 것이다. 물론 클라이언트가 느린 속도에서 회복하고 스트림을 계속 소비할 수 있도록 약간의 버퍼링을 원합니다. 그러나 이러한 트윗을 무기한 버퍼링할 수는 없습니다. 그것은 무한한 양의 메모리를 필요로 할 것입니다. 해결책은 간단합니다. 경계 버퍼를 사용합니다. 예를 들어 클라이언트가 이벤트를 내보내는 속도에 대처할 수 없는 경우 클라이언트에게 "우리는" 당신에게 배달할 메시지를 다시 대기열에 넣습니다. 현재 대기열이 60% 이상 찼습니다." 제한된 크기의 대기열, 서비스할 수 있는 느린 클라이언트 수를 기반으로 예측하고 서비스 수준과 노드 활용의 균형을 맞출 수 있기 때문에 이는 매우 좋은 전략입니다.

API 클라이언트의 대기열 및 버퍼 크기를 모니터링하는 것은 매우 흥미로운 지표이며 고객과의 일부 상호 작용을 유발할 수도 있습니다. 예를 들어, 추가 처리 능력을 제공하거나 어떤 방식으로든 클라이언트를 최적화하도록 제안할 수 있습니다. 물론 버퍼가 가득 차면 문제가 발생하지 않도록 애플리케이션을 저장하기 위해 뭔가를 해야 합니다. Twitter 예제에서 대답은 간단합니다. 클라이언트의 연결을 끊습니다(경고 메시지에는 항상 이에 대한 세부 정보가 포함됨). 그러나 이것이 유일한 옵션은 아닙니다. 특히 가장 오래된 요소가 오래된 경우 스트림에서 가장 오래되거나 최신 요소를 삭제할 수도 있습니다. 말할 필요도 없이 그러한 결정은 비즈니스 중심적이어야 합니다. 비록 Akka가 퀵 스타트 가이드에서 설명하는 오버플로 전략을 선택하는 것만큼 간단합니다.

Reactive Is an Architectural and Design Principle, Not a Single Library
>The whole is other than the sum of the parts.
Kurt Koffka

전체가 부분의 합보다 "크다"라는 이 인용문을 들어보셨을 것입니다. 그러나 Koffka가 전체 존재를 의미했기 때문에 실제 인용은 약간 다른 것으로 나타났습니다. 사실, 부분의 합이 아닌 다른 어떤 것입니다(예: 그림 2-3의 "보이지 않는" 삼각형과 같은). ). 인용문은 "반응성"이라는 용어와 함께 우리가 처한 상황에 맞습니다. "reactive" 접두사가 추가된 수많은 라이브러리를 쉽게 찾을 수 있을 뿐만 아니라, 일부 라이브러리는 리액티브의 의미를 라이브러리가 수행하는 유일한 작업(예: 스트림 처리)으로 변경하려고 시도합니다. 이것들이 훌륭한 빌딩 블록이라는 것을 깨닫는 것이 중요하지만 전체 문제를 거의 다루지 않습니다(대부분의 경우 회복력이나 탄력성을 다루지 않을 가능성이 높음). Reactive Systems에 대한 다음 장에서는 우리가 만들고 있는 응용 프로그램 내부의 멋진 프로그래밍 모델 외에 Reactive에 대해 더 자세히 알아볼 것입니다. 애플리케이션이 통신하는 방식과 필요에 따라 애플리케이션을 확장 및 축소할 수 있는 방법을 살펴보겠습니다.

![Image](..\images\why_reactive_2-3.png)
Figure 2-3. 삼각형의 선은 아직 그려지지 않았지만 흰색 삼각형의 가장자리를 볼 수 있습니다.

Reactive on the System Level
>One Actor is no Actor. Actors come in Systems.
Carl Hewitt, creator of the actor model of concurrent computation

조직 문제의 95% 이상이 개별 작업자가 아니라 시스템, 프로세스 및 방법에서 비롯됩니다. [...] 당신의 사람들은 최선을 다하고 있지만, 그들의 최선의 노력은 당신의 부적절하고 역기능적인 시스템을 보상할 수 없습니다.

>Changing the system will change what people do. Changing what people do will not change the system.
Peter R. Scholtes, The Leaders Handbook

실제로 우리는 단일 애플리케이션의 단일 인스턴스에 대해 거의 이야기하지 않습니다. 대신 다양한 기술을 사용하여 구현될 수 있는 여러 서비스로 구성된 시스템에 대해 이야기하고 각 서비스는 대기 시간과 가동 시간 요구 사항이 다릅니다. 이 장에서 알게 되겠지만, 이전 장에서 이야기한 많은 개념과 요구 사항은 시스템 수준으로 직접 변환됩니다.

우리는 종종 이것이 단지 시스템의 기술적 측면이라고 생각하게 됩니다. 나는 그것이 이야기의 일부일 뿐이라고 주장합니다. 응용 프로그램은 단어의 기술적 의미뿐 아니라 단어의 조직적 의미에서도 확장되어야 합니다. 분산 시스템(마이크로서비스가 좋은 예임)을 사용하면 책임을 여러 애플리케이션으로 나눌 수 있으며 각 애플리케이션에는 잘 정의된 책임이 있는 전용 팀이 있습니다. 따라서 분산 시스템은 조직의 확장을 가능하게 하고 도움을 줍니다. 이를 통해 종속성을 분리하고 프로젝트를 독립적으로 개발 및 배포할 수 있으므로 프로젝트 간의 엄격한 종속성을 제거할 수 있습니다. 이러한 독립성은 아마도 그러한 서비스가 소비되는 지구 반대편에 있는 다른 팀에서 서비스를 구축할 수 있도록 합니다. 일단 분산되면 팀이나 애플리케이션이 시간이나 공간적으로 얼마나 멀리 떨어져 있는지는 중요하지 않습니다.

Reactive Systems와 메시징 측면에서 생각하는 방식은 실제로 매우 간단하지만 그것이 쉽다는 의미는 아니라는 점을 깨닫는 것도 중요합니다. 차이점과 이 두 개념을 혼동하지 않는 것의 중요성은 Clojure 프로그래밍 언어의 창시자인 Rich Hickey가 RailsConf 2012 기조 연설에서 설명했습니다. 이 프레젠테이션에서 그는 "차이"가 "쉬운" 것이 우리에게 친숙한 것이라고 주장했습니다. 예를 들어, 지난 10년 동안 작업해 온 매우 복잡한 시스템의 다양한 모듈 간의 깊은 내부 및 숨겨진 종속성을 아는 것과 같이 정말 복잡한 일도 오랜 시간 연습하면 쉬워집니다. 어떤 것이 지금 당신에게 쉽다는 사실이 그것을 실제보다 더 단순하게 만드는 것은 아닙니다. 그것은 여전히 ​​​​복잡합니다. 반면에, 무언가는 "단순"할 수 있습니다. 즉, 핵심 개념과 아이디어를 "얻으면" 매우 간단하다는 것을 의미합니다. 그러나 이것이 그것을 배우는 것이 어렵지 않다는 것을 의미하지는 않습니다.

그래서 우리는 단순함과 복잡함을 대조하고, 쉬움과 어려움을 대조해야 합니다. 모든 형태나 형태의 분산 시스템은 어렵습니다. 조직 내에서 둘 이상의 컴퓨터 또는 둘 이상의 팀을 처리해야 하는 순간에는 단일 컴퓨터를 처리해야 하는 경우보다 상황이 더 어려워집니다. 사실 마이크로서비스는 분산 시스템이므로 하찮게 여겨서는 안 됩니다. 그러나 통신에 사용할 수 있는 수단은 단순할 수도 있고(예: 메시징) 복잡할 수도 있습니다(예: 풀링, 파이프라이닝, 회로 차단 및 차단된 데드 연결을 중단하는 시간 초과를 통한 요청/응답).

다음 섹션에서는 시스템 내의 통신 스타일을 살펴보고 확장성(기술적 및 조직적)을 검토하고 Reactive Services를 기존 코드 기반에 도입하는 방법을 제안하여 마무리합니다.

There’s More to Life Than Request-Response-JSON-over-HTTP
>HTTP/2 was meant as a better HTTP/1.1, primarily for document retrieval in browsers for websites. We can do better than HTTP/2 for applications.15
Ben Christensen, ReactiveSocket

매우 동기적인 요청-응답 패턴이 애플리케이션의 통신 패턴을 지배하는 것을 너무 자주 봅니다. REST가 나쁘다는 말은 아닙니다. 사실 RESTful 원칙을 사용하여 비동기 통신 패턴을 구현하는 것이 가능합니다. 여기서 유일한 문제는 실제로는 거의 그렇지 않다는 것입니다. 지난 몇 년 동안 많은 조직이 "HTTP를 통한 요청-응답 JSON" 사고 방식보다 REST 만트라와 이념에만 집중하고 있음을 보여주었습니다. 고맙게도 많은 팀은 Twitter의 Finagle RPC, Google의 새로운 GRPC(Google RPC) 라이브러리, 그리고 마지막으로 ReactiveSocket에 대한 Facebook 및 Netflix의 연구에서 보여주듯이 일부 사용 사례가 새로운 다가오는 프로토콜 또는 메시징 패턴에 의해 더 잘 제공될 수 있다는 것을 서서히 깨닫고 있습니다. "REST"라는 용어는 지난 몇 년 동안 HTTP를 통한 JSON을 의미하는 것으로 악화되었지만 반드시 그래야 하는 것은 아닙니다. 내가 이 차이점을 그리는 이유는 REST라는 용어를 만든 원본 간행물에서 어디에서나 HTTP를 언급하지만 어떻게든 개발자와 설계자는 REST를 엄격한 HTTP 바인딩 아키텍처 스타일로 이해하게 되었기 때문입니다. 이유 중 일부는 Fielding이 URI, HTTP 및 HTML IETF 작업 그룹에 참여했기 때문에 그의 작업이 어떤 식으로든 그들과 관련이 있음이 분명합니다.

서비스 간의 통신 패턴에 대해 이야기하기 전에 단일 서비스가 반드시 해당 서비스의 한 인스턴스에서 처리된다는 것을 의미하지는 않습니다. 예를 들어 이미지 크기 조정 서비스를 고려하십시오. 진입점은 단일 API 엔드포인트이며 서비스 사용자는 이를 "이미지 스케일링 서비스"(예: "이미지 스케일러가 다시 다운되었습니까?"에서와 같이)라고 합니다. 그러나 내부에서 동일한 서비스의 여러 인스턴스를 실행하고 내부 클러스터에서 들어오는 이미지의 균형을 조정할 수 있습니다. 서비스의 외부 API 및 상호 작용에 대한 절충점은 해당 서비스의 내부 통신에 대한 절충점과 다소 다를 수 있음을 인식하는 것이 중요합니다. 이것은 DDD 용어의 경계 컨텍스트에 직접 매핑됩니다. 단일 경계 컨텍스트 내에서 더 자유롭게 의사 소통하고 있습니다. 그러나 컨텍스트 경계를 넘어서야 하는 경우 필요한 일관성은 우리가 누구와 어떻게 의사 소통하는지에 따라 변경을 보장합니다. 이러한 차이점은 무엇보다 서비스가 일반적으로 단일 팀에서 소유한다는 사실에서 비롯됩니다. 즉, 캡슐화를 재발견했지만 이번에는 조직의 경계와 이러한 각 팀이 내부적으로 약간 다르게 작동한다는 사실의 결과입니다. 회사 내의 모든 커뮤니케이션을 동일한 RESTful 커뮤니케이션 스타일로 강제하는 대신 서비스의 내부 커뮤니케이션에 대한 제약을 완화하는 것이 종종 도움이 됩니다. 공개 API. 그림 3-1은 커뮤니케이션 스타일에 대한 외부 요구 사항과 내부 요구 사항의 차이점을 보여줍니다.

Pat Helland는 "외부 데이터 대 내부 데이터"라는 제목의 우수한 논문에서 데이터가 시스템의 "내부"(즉, 마이크로서비스가 소유한 내부 데이터 저장소)에 직면해야 하는 요구 사항에 본질적인 차이가 있다고 주장합니다. 및 "외부"(즉, 이 서비스의 소비자에게 데이터 표현을 내보낼 때). 특히 그는 내부 데이터 표현이 변경 가능하다고 주장합니다. 왜냐하면 동일한 데이터를 표현하는 더 효율적인 방법(예: SQL 스키마 변경)을 찾을 수 있기 때문입니다. 그러나 데이터의 외부 표현은 변경 불가능해야 합니다. 사용자가 연락처 목록을 얻을 수 있는 한 내부적으로 JOIN을 구현해야 했는지 또는 때때로 변경 가능하게 새로고침하는 미리 계산된 캐시에서 가져온 것인지는 중요하지 않습니다. 나는 같은 생각이 의사소통 패턴에도 적용된다고 주장하고 싶다. 외부적으로는 회사 내부(또는 외부)의 다른 팀이 사용할 수 있는 안정적이고 잘 정의된 RESTful API를 공개하거나 다른 사람들이 마음대로 사용할 수 있도록 사실을 공개할 수 있습니다(결과적으로 보다 이벤트 기반 아키텍처 ). 그러나 내부적으로는 우리의 요구에 가장 적합한 통신 프로토콜이 필요합니다. 예를 들어 내부적으로 바이너리 메시지 형식을 사용하여 실행 후 잊어버리기(fire-and-forget) 메시징을 선택할 수 있습니다.

![Image](..\images\why_reactive_3-1.png)
Figure 3-1. 데이터는 외부와 내부의 요구 사항이 다릅니다. 통신 패턴과 API 구축 및 발전 방식에 대해서도 마찬가지입니다.

엄격한 요청-응답 API의 문제 - RESTful API는 그 예 중 하나일 뿐입니다. SOAP는 개발자를 매우 유사한 접근 방식으로 유인합니다. 즉, 개발자가 할 수 있는 작업이 제한적이라는 것입니다. 예를 들어, HTTP 세계에서 이벤트 스트림에 대한 구독은 일종의 해킹이며 일반적으로 하나의 "무한" HTTP 응답을 반환하여 구현한 다음 줄 단위 JSON 데이터를 제공합니다. 이러한 API의 좋은 예는 Twitter 스트리밍 API입니다.

이 주제에 대해 논의할 때 다음과 같은 반론을 종종 들을 수 있습니다. "나는 REST와 완전히 동기화할 수 있습니다." 이 진술은 기술적으로 말하면 사실입니다. 그러나 기본적으로 메시징을 지원하는 솔루션과 비교할 때 구현 비용은 정말 기하급수적입니다.

RESTful 스타일로 구현될 때 비동기 작업 제출 API가 어떻게 보이는지 살펴보겠습니다. 먼저 제어 흐름을 분석한 다음 전체 수명 주기 동안 할당해야 하는 리소스 수를 살펴보겠습니다. 오늘날의 REST는 일반적으로 HTTP 위에 구현됩니다(꼭 그래야 하는 것은 아니지만, 원래 REST 문서에서는 HTTP와의 연관성에 대해 언급하지 않았습니다). 따라서 작업을 생성하기 위해 /jobs 서비스에 PUT할 수 있으며 작업 실행 요청이 수락되었음을 알리기 위해 201 Created 또는 202 Accepted로 응답합니다. 또한 작업이 완료되면 작업 결과가 있는 위치를 알려주는 Location 헤더도 포함됩니다. 반응하지 않는 클라이언트는 작업 상태에 대해 해당 위치를 폴링해야 합니다. 또한 발행된 요청에서 폴링을 처리하는 프로세스로의 매핑을 기억하기 위해 리소스를 유지해야 합니다. 초기 요청/회신 주기가 우리가 정말로 관심 있는 것(예: 작업의 결과 또는 진행 상황)을 알려주지 않더라도 나중에 작업의 결과를 찾을 방법이 없기 때문에 여전히 응답을 기다려야 합니다. .

Akka 또는 Erlang과 같은 메시징 기반 시스템에서 작업을 실행하고 싶다는 화재 및 잊어버리기 메시지를 보내 동일한 작업을 간단하게 수행할 수 있습니다. 결국 우리는 진행 상황에 대해 알리고 싶은 플래그를 해당 메시지에 포함할 수 있으며 보내는 쪽에서 완료됩니다. 작업이 완료되면 결과가 포함된 메시지를 다시 받게 됩니다. 언제 어디서 완료되는지 신경 쓸 필요가 없습니다. 이 솔루션에서 유지해야 하는 데이터 또는 상태의 오버헤드를 분석해 보겠습니다. 메시지를 수신할 주소 지정 가능한 엔터티만 있으면 됩니다(Erlang 용어로는 프로세스, Akka에서는 액터라고 함). 각각 약 400바이트로 매우 가벼울 수 있습니다. 이는 다양한 구현에 따라 다르지만 핵심 사항은 매우 작다는 것입니다. 이것이 우리가 다른 시스템과의 반응적 상호 작용에 대해 지불하는 모든 오버헤드입니다. 연결 설정, 왕복 왕복 및 폴링이 없습니다.

![Image](..\images\why_reactive_3-2.png)
Figure 3-2. 비동기식 HTTP 호출 스타일 API를 순수 메시징 프로토콜과 비교합니다. 반응 버전이 훨씬 낮은 동안 스레드 사용량을 확인하십시오.

이러한 종류의 문제를 해결하기 위한 HTTP의 대체 패턴은 수년 동안 발명되었지만 매우 무거우며 너무 많은 작업, 작업 및 클라이언트가 발생하는 현대 인터넷에서 살아남을 수 없습니다. 동시에. 그러나 확장성의 약점을 보여주기 위해 이러한 패턴 중 일부를 해결해 보겠습니다. HTTP 지지자들은 우리가 처음에 장기 실행 HTTP PUT 호출을 사용할 수 있었다고 제안할 수 있으므로 작업이 완료될 때까지 요청을 "열린" 상태로 유지합니다.

확장성에 관한 것만이 아니라는 사실을 깨닫는 것도 중요합니다. 일반 HTTP로 이러한 API를 설계할 때 내려야 하는 결정의 수가 기하급수적으로 증가하고 있습니다. 통화를 차단할까요? 어떤 방법을 사용해야 할까요? 클라이언트에게 어떻게 폴링을 하라고 말합니까? 대신 WebSocket을 사용해야 합니까? 서버에서 보낸 이벤트는 어떻습니까? 메시징을 사용하면 간단합니다. 무언가를 원할 때 메시지를 보내고 무언가가 완료되면 메시지를 받습니다. 따라서 이러한 관점에서 시스템을 설계할 때 큰 단순화와 덜 골칫거리이기도 하며 구현 세부 사항에 대해 논의하는 대신 실제 작업에 집중할 수 있습니다.

Surviving the Load…and Shaving the Bill!
Reactive Systems의 가장 흥미로운 측면은 다양한 수신 트래픽에 직면하여 탄력적으로 확장할 수 있는 기능입니다. 확장은 일반적으로 두 가지 목적 중 하나를 수행합니다. 하나는 확장(더 많은 시스템 추가) 및 확장(더 강력한 시스템 추가) 또는 축소를 통해 애플리케이션이 차지하는 리소스 수를 줄이는 것입니다.

"탄력 있는"이라는 단어는 점점 더 두드러지게 되었습니다. 그 의미가 잘 알려져 있고 사랑받는 용어 "확장성"과 매우 유사하지만 주목해야 할 중요한 변화입니다. 특히 클라우드 초기에는 쉽게 올인하고 결국 실제로 처리하고 있던 로드에 과도하게 프로비저닝될 수 있습니다. 새 노드를 추가하거나 클러스터에 결합하거나 로드 밸런서 뒤에 숨기는 것과 같이 클라우드에서 확장하는 것은 다소 사소하기 때문입니다. 스핀업된 노드에서 다소 합리적인 활용 수준을 회복하는 것이 사소하지 않다는 것이 밝혀졌습니다. 이것이 최근 컨테이너 및 클러스터 오케스트레이터(예: Mesos)의 추세가 상승하는 이유입니다. 우리는 지난 몇 년 동안 애플리케이션을 과도하게 프로비저닝했습니다. 오버 프로비저닝 자체는 나쁜 것이 아닙니다. 그것은 우리가 클러스터에 더 많은 노드를 추가하는 동안(아마도 새로운 마케팅 캠페인이 정말로 성공적이었을 수도 있음) 트래픽의 갑작스러운 급증을 견딜 수 있는 "버퍼"를 제공합니다. 하지만 로트에 의한 과잉 프로비저닝은 우리가 실제로 사용하지 않은 것에 대한 큰 인보이스와 같은 큰 문제입니다.

우리는 시스템의 확장성에 대해 말할 때 개발자가 스케일 아웃 또는 스케일 업에 집착하고 스케일 다운 부분이 어떻게 든 손실된다는 것을 발견했습니다. 저는 규모 축소가 규모 확장/축소만큼 중요하다고 주장합니다. 결국 극심한 교통 수요가 해소되면 높은 비용을 지불할 필요가 없으며 물론 에너지를 절약하고 환경 친화적이기를 원합니다. 잘. Mesos 및 Kubernetes와 같은 새로운 도구는 애플리케이션 배포에 대한 컨테이너 중심 접근 방식과 함께 앱의 정상적인 작동을 위해 더 많은 작업이 없는 미래로 가는 길을 닦고 있습니다.

Netflix 및 Gilt(인기 있는 플래시 판매 사이트)에서 대중화된 흥미로운 확장 패턴은 예측적 확장입니다. 이 확장 패턴에서는 급증이 언제 발생하는지 알 수 있으므로 해당 기간 동안 서버를 사전에 프로비저닝하고 트래픽이 감소하기 시작하면 다시 클러스터 크기를 점진적으로 줄이십시오. 여기서 재미있는 말장난에 빠질 수 있습니다. "반응적 확장"보다 "적극적 확장"이 더 낫습니까? 아니요, 그렇지 않습니다. Reactive Services는 서비스 확장을 위한 조력자이기 때문입니다. 반면에 사전 예방적 확장은 언제 확장할지 결정할 수 있는 기술입니다. 예를 들어 Gilt(프로비저닝 전략에 대해 매우 개방적임)와 같은 플래시 판매 사이트는 플래시 판매가 활성화된 한낮의 트래픽 급증이 매우 높습니다. 따라서 여기서 확장의 사전 예방적 부분은 예측 가능하기 때문에 높은 로드가 서버에 도달하기 전에 노드를 스핀업할 수 있음을 의미합니다. 이는 이러한 서비스가 사후 대응적이라는 것과 관련이 있습니다. 결국 앱을 전혀 확장할 수 없다면 사전 예방적으로 앱을 확장할 수 없습니다.

Without Resilience, Nothing Else Matters
>Resilience is the ability of a substance or object to spring back into shape. The capacity to recover quickly from difficulties.
회복력은 물질이나 물체가 다시 모양으로 튀어 나오는 능력입니다. 어려움에서 빨리 회복하는 능력.
Merriam Webster

우리는 성능, 확장성, 메시징 패턴 및 반응형의 다양한 기타 측면에 대해 많은 논의를 했습니다. 마지막으로 가장 중요한 특성인 회복력으로 돌아가 보겠습니다. 결국, 문제가 발생하면 완전히 사용할 수 없게 되는 초고속 확장 가능한 시스템을 갖는 것은 도움이 되지 않습니다.

결국, 시스템을 사용할 수 없는 경우 시스템이 얼마나 빠르고 반짝이며 훌륭한지는 중요하지 않습니다. Reactive Systems는 일반적으로 장애가 발생한 노드를 새로운 정상 노드로 교체하거나 단순히 시스템에 과부하가 걸렸을 트래픽 증가에 직면하여 단순히 노드를 추가함으로써 장애를 처리합니다. 그런 의미에서 이러한 시스템은 안티프래질, 즉 스트레스 하에서 생존할 수 있을 뿐만 아니라 실제로 스트레스를 받으면 개선되는 특성으로 생각할 수 있습니다.

탄력성에 대한 장에서 암묵적으로 논의한 또 다른 반패턴은 레거시 시스템이 때때로 값비싼 공통 리소스에 대한 액세스를 공유하는 경향이 있다는 것입니다. 애플리케이션 수준에서 이는 변경 가능한 상태에 대한 공유 동시 액세스로 나타납니다. 시스템 수준에서는 종종 단순히 공유 데이터베이스 또는 유사한 리소스이기 때문에 훨씬 쉽게 발견할 수 있습니다. 이러한 리소스의 공통 주제는 모든 서비스가 작동하기 위해 공유 상태에 액세스해야 한다는 것입니다. 실제로 2016년 Reddit 중단은 이러한 공유 서비스의 오작동으로 인해 발생했습니다. 즉, 잠재적인 단일 실패 지점이었고 전체 사이트를 다운시켰습니다.

Reactive Systems는 액터에 대해 이야기할 때 이미 논의한 "자신의 데이터 소유" 패턴을 따릅니다. 동일한 패턴이지만 지금은 시스템 수준입니다. 시스템이 ZooKeeper에 의존하는 대신 주변 환경에 대해 더 많은 상태를 내부적으로 유지했다면 아마도 정전에서 살아남을 수 있었을 것입니다(예를 들어, 공유 리소스가 실패하면 "불확실성" 시간 초과가 bbn 트리거되어 작업을 제공할 수 있습니다. 팀은 이러한 서버가 종료되기 전에 대응할 시간이 더 많습니다). 엄격하게 피어 투 피어(peer-to-peer) 및 마스터리스(masterless) 시스템은 본질적으로 단일 특수 리소스 문제를 피하기 위해 자체적으로 구조화되기 때문에 훨씬 더 좋습니다.

Building Blocks of Reactive Systems
>We build too many walls and not enough bridges.
Joseph Fort Newton

시스템은 결코 진공 상태에 있지 않으며 동일한 부품으로 구성되지도 않습니다. 현실 세계는 훨씬 더 다양하며 이 사실을 무시하려는 시도는 필연적으로 실망으로 이어지며 최악의 경우 실패로 이어집니다.

대신, 우리는 이러한 다양성을 인식하고 시스템의 다양한 부분이 구축된 영역에서 전문화될 수 있는 강점으로 전환합니다. Reactive on the System Level에서 설명한 대로 이러한 구성 요소를 하나씩 추가하여 시스템 아키텍처를 사후 대응 원칙으로 점진적으로 이동할 수 있습니다. Reactive System으로의 여정은 길 수 있지만 이 보고서 전체에서 논의한 방식으로 아키텍처를 개선할 것이기 때문에 가치가 있는 것입니다. 또한 낙담하지 않고 시스템에서 이동할 가치가 있는 부분과 그렇지 않은 부분을 신중하게 판단하는 것이 중요합니다. 예를 들어, 새로운 기능을 구축해야 하는 경우 레거시 코드베이스를 확장하는 대신 반응형 마이크로서비스로 구축하고 기존 시스템과 통합하는 것이 가능한지 생각해 보세요. 그린필드 시스템을 구축할 수 없는 경우 이전에 논의한 대로 스트랭글러 패턴을 적용하고 시스템의 특정 부분에 필요한 빌딩 블록을 선택하세요.
그렇다면 Reactive Systems를 구축하는 데 사용할 수 있는 다른 빌딩 블록은 무엇입니까? 우리는 이미 그 중 몇 가지를 암묵적으로 논의했지만 다양한 기술을 모두 다룰 기회는 없었습니다.

예를 들어 스트리밍의 경우와 마찬가지로 Akka Streams와 Akka HTTP 또는 RxJava를 사용하여 스트리밍 API를 구축하고 사용하는 방법에 대해 논의했습니다. 그러나 우리는 야간 배치 작업에서 스트리밍 데이터 분석의 보다 반응적인 파이프라인으로 이동하는 것에 대해 이야기하지 않았습니다. Apache Spark, Flink 또는 Gear Pump와 같은 이러한 기술을 사용하면 애플리케이션의 응답성을 개선할 수 있습니다. 야간 배치가 완료되어 고객에게 보고서를 보낼 때까지 기다리는 대신 데이터를 임시로 또는 스트리밍 방식으로 처리하여 고객에게 더 빠른 피드백을 제공할 수 있습니다.

언급할 공간이 거의 없었던 다른 주제는 클러스터 스케줄러 및 Mesos 및 Mesosphere DC/OS와 같은 플랫폼입니다. Reactive Services를 구축했으면 이제 이를 어딘가에 배포할 차례입니다. Reactive Services가 제공하는 가능성을 활용하려면 이러한 기능을 지원하는 패브릭이 필요합니다. 좋은 예는 온프레미스 또는 클라우드에 배포하고 애플리케이션 인스턴스를 클라우드 리소스에 할당하는 방식을 표준화할 수 있는 Mesos입니다. 확장성과 복원력을 염두에 두고 구축된 반응형 애플리케이션 덕분에 Mesos와 같은 스케줄러는 시스템에 대한 압력이 변경됨에 따라 앱의 인스턴스를 종료하고 시작할 수 있습니다.

Introducing Reactive in Real-World Systems
>Fully async architecture has [measurable] benefits. However I don’t expect to see a software system like that. Instead, we deal with mixed-codebases.
완전 비동기 아키텍처에는 [측정 가능한] 이점이 있습니다. 그러나 나는 그런 소프트웨어 시스템을 볼 것으로 기대하지 않습니다. 대신, 우리는 혼합 코드베이스를 다룹니다.
Ben Christensen

일상 업무의 현실은 완전히 새롭게 시작할 기회가 거의 없다는 것입니다. 비록 우리가 미개발 프로젝트를 가지고 있다 하더라도 관련성이 있으려면 기존 시스템과 통합해야 하며, 이러한 프로젝트는 오늘날 우리가 바라는 수준의 복원력과 의미 체계로 구축되지 않았을 수 있습니다. 우리는 레거시 시스템을 무시하는 것이 건전한 접근 방식이라고 생각하지 않습니다. 레거시 시스템은 제 시간에 무언가를 전달하는 데 성공했기 때문에 존재합니다. 이 단순한 사실을 받아들이게 되면 반응형 아키텍처와 같은 새로운 기술을 채택하고 앞으로 나아가기 위한 생산적인 방법을 찾을 수 있습니다. 이 섹션에서는 기존 생태계에 새로운 기술을 도입하기 위한 성공적이고 입증된 접근 방식을 강조하는 것을 목표로 합니다.

특히 다른 패러다임이나 언어로 이동할 때 기존 코드 기반에 변경 사항을 도입하는 방법 중 하나는 그러나 종종 고의적으로는 아닙니다. 개념은 다소 단순하며 그림 4-1에 설명되어 있습니다.

![Image](..\images\why_reactive_4-1.png)
Figure 4-1. 새로운 Reactive API 뒤에 오래된 구현을 숨기기 위해 strangler 패턴을 적용하고 시스템의 Reactive 부분에 새로운 기능을 도입하고 필요에 따라 이전 기능을 새 코어로 마이그레이션합니다.

여기서 아이디어는 실제 문제에 부딪힐 때까지 작동하는 레거시 코드를 다시 작성하지 않는 것입니다. 이 시점에서 새 스타일로 다시 작성하는 것을 고려할 수 있습니다(하지만 강제는 아님). 이 패턴은 어떻게 담쟁이 식물은 그들이 자라는 나무를 목 졸라 죽입니다. 여기서 아이디어는 동일합니다. 새 시스템은 이전 시스템을 중심으로 확장되며 이전 시스템에서 아무 것도 다시 작성할 필요가 없습니다. 한편, 시스템의 나머지 부분은 더 반응적인 개발 스타일로 넘어갈 수 있으며, 필요한 경우 내부를 재작성할 수 있습니다. 이는 주로 이전 코드베이스를 과소평가하거나 이해하지 못하기 때문에 종종 치명적인 실패로 끝나는 고위험 "빅뱅(big bang)" 재작성을 방지하는 데 도움이 됩니다.

Reactive, an Architectural Style for Present and Future
>I know; you did send me back to the future. But I’m back. I’m back from the future.
Marty McFly, Back to the Future

리액티브가 단일 특정 기술이나 라이브러리에 관한 것이 아님을 일찍 깨닫는 것이 중요합니다. 특정 라이브러리를 설명하는 데 이 책을 사용하는 대신 많은 시간과 공간을 사용하여 라이브러리의 핵심 개념을 자세히 살펴보았습니다. 이 지식을 통해 여정을 계속하고 어떤 도구가 가장 적합하고 이 새로운 프로그래밍 패러다임으로 나아가는 데 도움이 될지 스스로 결정할 수 있어야 합니다. 개발자가 분산 시스템을 숨기려고 할 때 마치 로컬 실행의 특별한 경우인 것처럼 과거의 실수로부터 배웠다는 사실도 매우 흥미롭습니다. CORBA 및 무거운 SOA 프로세스와 같은 동기식 RPC 시스템에서 발생하는 실수. 우리는 이러한 실험을 통해 좋은 교훈을 얻었고 이제 그 어느 때보다 네트워크를 수용했다고 생각합니다. 그리고 어떤 희생을 치르더라도 실패를 피하는 대신 시스템에 이를 수용하여 시스템이 확장하고 수용할 수 있도록 합니다.

물론 사용할 수 있는 몇 가지 훌륭한 도구가 있습니다. 하지만 잘못 사용하면 최고의 도구나 라이브러리라도 문제를 스스로 해결할 수 없습니다. Agile이 IT 산업을 인수했을 때와 같은 상황을 기억할 수 있습니다. 그럴만한 이유가 있습니다. 그러나 당시 많은 팀이 팀에 어떤 도움이 될 것인지에 대해 너무 많이 생각하지 않고 "일일 스탠드업"을 적용했습니다. 대신, 그들은 그것을 "책에 따라" 엄격하게 적용했고, 그들이 제자리에 있던 나머지 깨진 프로세스를 해결하지 못했을 때 애자일 전체를 비난했습니다. 요즘에는 Agile 및 Lean 방식이 없는 소프트웨어 개발을 상상하기 어렵습니다. 그러나 모든 방법론과 마찬가지로 여전히 오해의 여지가 있습니다.

따라서 리액티브를 채택할 때 생각을 하고 앞으로 나아가기 전에 원칙을 이해하는 것이 중요합니다. 이 보고서가 정확히 이를 수행하고 귀하와 귀하의 팀이 구축한 시스템에 대한 최상의 결정을 내리는 데 도움이 되기를 바랍니다.